# LogTrust-XAI
Prototype for interpretable anomaly detection on cloud operations logs.

## Overview
This proof-of-concept (PoC) explores how explainable machine learning models
(such as Decision Trees and SHAP) can support reliable AI-driven operations (AIOps)
by providing transparent reasoning for anomaly detection.

Developed as preliminary work for the University of Manchester MPhil project:
**"Towards Explainable and Reliable AI-Driven Operations"**

## Structure
- `/data/` - placeholder for synthetic or anonymised log data
- `/notebooks/` - experiments and visualisations
- `/src/` - model and explanation modules

## Next Steps
1. Train baseline model on LogHub or Azure synthetic telemetry.
2. Apply SHAP for local explanations.
3. Evaluate interpretability and reliability metrics.

## Related Projects
- [PyReason-Ops](https://github.com/ShrawantiA/PyReason-Ops)
- [CloudExplain](https://github.com/ShrawantiA/CloudExplain)

## License
MIT License Â© 2025 Shrawanti Anabattula
